1. 
6920 / 872 / 1821 train/dev/test examples
=====Train Accuracy=====
Accuracy: 6854 / 6920 = 0.990462
Precision (fraction of predicted positives that are correct): 3577 / 3610 = 0.990859; Recall (fraction of true positives predicted correctly): 3577 / 3610 = 0.990859; F1 (harmonic mean of precision and recall): 0.990859
=====Dev Accuracy=====
Accuracy: 654 / 872 = 0.750000
Precision (fraction of predicted positives that are correct): 345 / 464 = 0.743534; Recall (fraction of true positives predicted correctly): 345 / 444 = 0.777027; F1 (harmonic mean of precision and recall): 0.759912
Time for training and evaluation: 3.27 seconds
2. 
t th epoch I am referring to in this explanation is according to traditional counting. So, 2nd epoch means 2nd iteration with index 1 at my code (the code iterates through (0, epochs)), not 3rd iteration.
The first schedule I tried was starting at 1.3 and decreasing by 0.3 every 4 epochs starting from second epoch. (15 epochs total, so decrease would happen at 2, 6, 10, 14 epochs)
This results in train accuracy of 0.98 and dev accuracy of 0.73 - 0.75. Dev accuracy of between 0.74 and 0.75 was majority. 
The second schedule I tried was starting at 1 and decreasing the step size by 1/t every 4 epochs starting from the second epoch. (15 epochs total, so decrease would happen at 2, 6, 10, 14 epochs)
This results in train accuracy of 0.97 - 0.98 and dev accuracy of 0.73 - 0.75. Dev accuracy of between 0.73 and 0.74 was majority.
Both schedules have similar train accuracy, with the second being slightly lower. 
The second schedule of decreasing step size by 1/t generally had a lower dev accuracy of around 0.73 - 0.74 while the first schedule generally had 0.74 - 0.75.

3. 
Positive:
sweet
beautifully
hilarious
world
remarkable
powerful
solid
rare
appealing
eyes

Negative:
worst
TV
copy
pretentious
stupid
lacking
none
car
dull
contrived

10 words with highest positive weight tend to be positive when considering the meanings of the words, such as sweet, beautifully, powerful, etc. 
There are some words that are not directly positive but can be used with the positive words together, such as world or rare. 
10 words with lowest negative weight tend to convey negative meanings in English, such as worst, pretentious, stupid, etc.
However, there are some words that seem irrlevant, such as TV and car. 

4.
Training accuracy is around 0.98 while devlopment accuracy is around 0.74 which is lower than training accuracy. The slight difference could be due to discarding words unseen from the training data and development data being different from the training data in general. However, greater difference could be due to overfitting to the training data. Also, hyperparameter settings such as epochs and step size could be contributing to the overfitting and lower accuracy in development. 

5. 
6920 / 872 / 1821 train/dev/test examples
=====Train Accuracy=====
Accuracy: 6671 / 6920 = 0.964017
Precision (fraction of predicted positives that are correct): 3523 / 3685 = 0.956038; Recall (fraction of true positives predicted correctly): 3523 / 3610 = 0.975900; F1 (harmonic mean of precision and recall): 0.965867
=====Dev Accuracy=====
Accuracy: 673 / 872 = 0.771789
Precision (fraction of predicted positives that are correct): 385 / 525 = 0.733333; Recall (fraction of true positives predicted correctly): 385 / 444 = 0.867117; F1 (harmonic mean of precision and recall): 0.794634
Time for training and evaluation: 4.06 seconds

6. 

7. 

